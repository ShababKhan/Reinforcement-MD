# Project Blueprint: Reinforced Molecular Dynamics (rMD) Replication

**Scientific Paper:** Reinforce molecular dynamics: Physics-infused generative machine learning model explores CRBN activation process (Kolossváry, Coffey, bioRxiv pre-print)

## Introduction

This document outlines the plan to replicate the Reinforced Molecular Dynamics (rMD) methodology, focusing on building the informed autoencoder structure and the associated data processing pipeline necessary to model the CRBN open-to-closed conformational transition based on pre-computed free energy data.

## Methodology

*   **Core Principle:** Implementation of a dual-loss autoencoder linking latent space to Collective Variable (CV) space using a Free Energy (FE) map derived from advanced MD.
*   **Architecture:** Custom Encoder-Decoder chain with fully connected layers matching the structure implied by Fig. S2 and Fig. 2.
    *   **Encoder:** Flattens Cartesian coordinates -> Gradually shrinking hidden layers -> 3D Latent Space (LS).
    *   **Decoder:** 3D LS -> Gradually expanding hidden layers -> Reconstructed Cartesian Coordinates.
*   **Loss Functions:**
    1.  **Loss 2 (`predLoss`):** Standard reconstruction loss (e.g., MAE/RMSD) between input structure and decoded output structure. **Goal:** Structure fidelity.
    2.  **Loss 1 (`latentLoss`):** A mapping loss between the latent space (LS) coordinates output by the encoder and the corresponding CV coordinates from the simulation metadata. **Goal:** Inject physical context.
*   **Optimization:** Simultaneous optimization of $\text{Loss}_1$ and $\text{Loss}_2$ (weighted sum).
*   **Generation:** Sampling coordinates from the FE map (which lives in the CV space), mapping them to the LS, and decoding to full structures.
*   **Path Generation:** Fitting a B-spline to anchor CV points and feeding the points along the spline to the decoder.
*   **Code Standard:** All Python code must strictly adhere to **PEP 8** style guidelines.

## Technology Stack & Dependencies

| Category | Component | Required Libraries/Software | Notes |
| :--- | :--- | :--- | :--- |
| **Core Environment** | Implementation Language | **Python** | Must adhere to PEP 8. |
| **Machine Learning**| Autoencoder Implementation | PyTorch (Recommended) or TensorFlow | |
| **Numerical/Data** | Array manipulation/Handling simulation data | NumPy | Essential for handling Cartesian coordinates and vector operations. |
| **Structural Prep** | Structure Superposition | MDAnalysis (or similar) | Needed for frame alignment/superposition. |
| **Path Fitting** | B-Spline Fitting | SciPy (or specific spline library) | For fitting the path through anchor CV points. |
| **Utilities** | Plotting/Visualization | Matplotlib | For replicating figures like Fig 2, 3, and 4. |

## Extrapolated Work: CRBN Specifics & Inputs

*   **Input Data Structure:** Length 9696 vectors (Flattened heavy atom coordinates for CRBN only, as DDB1 motion was negligible).
*   **Latent Space Dimension:** 3 dimensions (matching $\text{CV}_1, \text{CV}_2, \text{CV}_3$ from Fig. 3).
*   **Activation Function:** Swish ($x\sigma(x)$) for all linear layers except the LS layer.
*   **Optimizer:** Adam (as used in the original paper).
*   **Training Parameters:** 10,000 rounds, Batch Size 64.
*   **Pre-processing:** Input structure superposition must be performed relative to an initial frame.
*   **Post-Processing Note:** Rosetta/Rosie server integration is **SCOPE-OUT** for the initial software replication, but the Python module must include a function to handle the *output* structure cleaning steps and document the expected inputs for external tools.

## Agile Project Plan Summary

*   **Sprint 1:** Core ML Model Implementation (Data Prep, Network Architecture, Dual-Loss Training up to loss convergence).
*   **Sprint 2:** Advanced Features & Verification (Structure Generation, B-Spline Path Sampling, Final Validation).

## Tests

*   **Unit Tests:** Verify correctness of data loading, coordinate flattening/unflattening, and ensemble superposition.
*   **Integration Test 1 (Loss Calculation):** Verify $\text{Loss}_1$ and $\text{Loss}_2$ calculate correctly according to the described geometry and loss functions.
*   **Integration Test 2 (Trained Convergence):** Verify that after training, Loss 1 approaches $\approx 1.0$ and Loss 2 approaches $\approx 1.6$ (Å RMSD).
*   **Validation Test (Structural Fidelity):** Validate that structures generated from coordinates *within the training distribution* of the LS yield an average all-heavy-atom RMSD of $\approx 1.2\text{ Å}$ or better against their true corresponding MD frames.
*   **Validation Test (Physical Correlation):** Verify that structures generated by sampling the FE map (in CV space) populate regions corresponding to the known low-energy areas (Green in Fig. 3).

---

*Self-Correction Check: All scientific elements mapped to tasks (M1-M13, F1-F4, S1-S2) are covered in the Agile Plan.*